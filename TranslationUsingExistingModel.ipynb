{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3a18838-c5a5-4a7f-89ca-9ed795c93bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "import tensorflow as tf\n",
    "import string\n",
    "import re\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "import random\n",
    "import subprocess\n",
    "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu, SmoothingFunction\n",
    "np.random.seed(42)\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
    "from transformers import MarianMTModel, MarianTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51bcce7c-cda1-42dd-9292-c5eb821667fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_file = \"C:\\\\Users\\\\Emanuel\\\\Desktop\\\\AD\\\\TP2\\\\por.txt\"\n",
    "with open(text_file, encoding=\"utf8\") as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "text_pairs = []\n",
    "for line in lines:\n",
    "    en, pt = line.split(\"\\t\")\n",
    "    text_pairs.append((f\">>por<< {en}\", pt))\n",
    "del lines\n",
    "\n",
    "text_pairs = random.sample(text_pairs, 100)\n",
    "en_text = [pair[0] for pair in text_pairs]\n",
    "pt_text = [pair[1] for pair in text_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d701608e-3258-4f04-b0cc-10be77fb33dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"C:\\\\Users\\\\Emanuel\\\\Downloads\\\\opus-mt-tc-big-en-pt\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38ae1430-3363-466b-8571-1256b88aced7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4-gram BLEU: 0.46\n"
     ]
    }
   ],
   "source": [
    "bleu_pt_list = []\n",
    "bleu_translation_list = []\n",
    "for i in range(len(en_text)):\n",
    "    # Dividir o pares em listas de palavras, meter tudo em lower case e retirar start/end\n",
    "    expected_pt_text = pt_text[i].lower().split(\" \")\n",
    "    en_instance = en_text[i]\n",
    "\n",
    "    if len(expected_pt_text) <= 4:\n",
    "        continue\n",
    "        \n",
    "    translated = model.generate(**tokenizer([en_instance], return_tensors=\"pt\", padding=True))\n",
    "    translated = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "    translated = translated.lower().split(\" \")\n",
    "    # Filtrar strings vazias\n",
    "    expected_pt_text = list(filter(None, expected_pt_text))\n",
    "    translated = list(filter(None, translated))\n",
    "    bleu_pt_list.append([expected_pt_text])\n",
    "    bleu_translation_list.append(translated)\n",
    "\n",
    "# Calcular 4-gram BLEU\n",
    "gram4 = corpus_bleu(bleu_pt_list, bleu_translation_list, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=SmoothingFunction().method1)\n",
    "print(f'4-gram BLEU: {round(np.mean(gram4),3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9542acd3-e1f5-4e1a-a7bb-01dbf5094904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "somos as primeiras a chegar.\n",
      "somos os primeiros a chegar.\n",
      "-\n",
      "tom tomou algumas decisões ruins recentemente.\n",
      "tom tomou algumas decisões ruins recentemente.\n",
      "-\n",
      "o natal cai num domingo este ano.\n",
      "o natal cai no domingo deste ano.\n",
      "-\n",
      "pensei que você precisava de dinheiro.\n",
      "pensei que precisavas de dinheiro.\n",
      "-\n",
      "o vapor embaçou meus óculos.\n",
      "o vapor enevoou os meus óculos.\n",
      "-\n",
      "essa é uma bela de uma suposição.\n",
      "é uma suposição muito grande.\n",
      "-\n",
      "esse piano é muito barato.\n",
      "este piano é muito barato.\n",
      "-\n",
      "tom derramou água fria sobre a cabeça.\n",
      "tom derramou água fria sobre sua cabeça.\n",
      "-\n",
      "o tom estava um pouco embriagado.\n",
      "tom era um pouco gordinho.\n",
      "-\n",
      "\"tom é seu namorado, não é?\"\n",
      "\"o tom é o teu namorado, não é?\"\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\" \".join(bleu_pt_list[i][0]))\n",
    "    print(\" \".join(bleu_translation_list[i]))\n",
    "    print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b772ec3d-0862-4dc8-ae6b-84ff784f1647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
